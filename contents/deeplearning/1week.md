# **딥러닝의 시작 <span style="color:green">_with tensorflow</span>**

 ### **◇ 인공지능**
학습,인식,추론 등 인간이 할 수 있는 작업과 할 수 없는 작업을 컴퓨터가 할 수 있도록 히는 것   

 ### **◇ 머신러닝** 
 인공지능의 하위 집합으로, 자동으로 데이터에서 규칙을 학습하는 알고리즘 (대표적으로 사이킷런-scikit-learn-라이브러리를 사용)   

 ### **◇ 딥러닝**  
 머신러닝의 하위 집합으로, 머신러닝의 알고리즘 중 인공 신경망(artificial neural network)을 기반으로한 방법
   
---
## **머신 러닝 프로세스**

***1. 문제 정의 및 데이터 준비하기***  
 >우리에게 주어진 데이터와 정답의 형태를 파악하고 문제를 정의하는 과정

***2. 학습하기***
> 좋은 모델을 선택하여 변경하고 학습하는 반복의 과정

***3. 추론 및 평가***
> 주어진 상황에 맞게 평가 기준을 세우고 최종 모델을 선택하는 과정

---

## **용어 살피기**

### ***1. 데이터 준비하기***
- 클래스 불균형   
> 클래스가 불균형하게 분포되어 있는 것을 말하며, 주로 특이한 경우가 포함된 데이터에서 볼 수 있다. 이러한 문제를 **이상 탐지** 라고 부른다.
- ✓과소표집(UnderSampling)과 과대표집(OverSampling)
> **과소표집**은 다른 클래스에 비해 상대적으로 많은 클래스의 개수를 줄이는 것이다.이를 통해 균형을 유지하지만, 유용한 정보가 버려질 수 있다.

> **과대표집**은 데이터를 복제하는 것이다. 정보를 일찌 않기 때문에 학습용 데이터에서 높은 성능을 보이지만 실험용 데이터에서의 성능은 낮아질 수 있다.
- 회귀(Regression)
> 하나 또는 여러개의 특징으로 통해 연속적인 숫자로 이루어진 정답을 예측하는 것으로, 특징을 독립변수, 정답을 종속변수라고 한다.
- 분류(이진 분류,다중 분류,다중 레이블 분류)
> 데이터셋에서 미리 정의된 여러 클래스 중 하나를 예측하는 것으로, 무언가의 종류를 구분하는 것이 해당된다.
- 원핫 인코딩
> 하나의 클래스만 1이고 나머지 클래스는 0인 인코딩  
ex) true:[1,0] 
false:[0,1]
- ✓교차 검증
> 모델의 타당성을 검증하는 방법으로, **학습데이터**, **검증 데이터**, **테스트 데이터**로 나누어서 사용한다.

### ***2.학습하기***
- 하이퍼파라미터
> 경험에 의해 결정되는 요소를 의미하며,최적의 값을 찾기위한 과정을 하이퍼파라미터 튜닝이라고 한다.  
ex)학습률, 배치 크기, 에폭, 드롭아웃률
- ✓배치(Batch)와 배치 크기(Batch size)
> **배치 학습**은 하나의 데이터를 사용하거나, 전체 데이터를 사용해서 학습을 시킬 때의 단점을 보완하기 위해 사용한다.<br>
**배치 크기** 는 전체의 dataset을 여러 작은 그룹으로 나누었을 때 작은 그룹 하나에 해당되는 데이터의 수를 의미한다.  
🔎 ex) 1000개의 dataset은 10개의 배치와 100개의 배치 크기로 나뉜다.
- 에폭(Epochs)과 스텝(Steps)
> **에폭**은 전체 데이터를 사용하여 학습하는 횟수를 의미한다. 전체 데이터를 10회 반복해 학습시킨 것을 10 에폭이라 말한다.  
**스텝(전체 데이터 사용 수/배치 크기)** 은 모델이 가진 파라미터(or 가중치)를 1회 업데이트하는 것을 의미한다.
- 지도 학습(Supervised Learning)
> 학습 데이터에 정답이 포함된 것을 의미한다.
ex)회귀와 분류
- 비지도 학습(UnSupervised Learning)
>학습 데이터에 정답이 포함되어 있지 않은 것을 의미한다.
- 과대적합(Overfitting)과 과소적합(Underfitting)
> **과대적합**은 모델이 학습 데이터에서는 좋은 성능을 보이지만 새로운 데이터에 대해서는 좋은 성능을 보이지 못하는 결과를 의미한다.
***이를 해결하기 위해,***
>1. 학습데이터를 다양하게, 많이 수집한다.
>2. 정규화를 이용해 규칙을 단순화 시킨다.
>3. 이상치를 제거한다.

>**과소적합**은 모델이 학습 데이터를 충분히 학습하지 않아 모든 성능에서 나쁘다는 것을 의미한다.(why? 많은 데이터를 보지 못했기 때문에 새로운 데이터를 구분하지 못함)    
***이를 해결하기 위해,***  
>1. 학습 데이터를 다양하게, 많이 수집한다.
>2. 더 복잡한 모델을 사용한다.
>3. 모델을 충분히 학습시킨다.

### ***3.평가하기***
- 혼동행렬(confusion Matrix)
> **혼동행렬**은 주로 알고리즘이나 모델의 성능을 평가할 때 많이 사용합니다.
![](./images/2022-05-08-17-20-09.png)
**True Positive(TP)** : 실제 True인 정답을 True라고 예측 (정답)   
**False Positive(FP)** : 실제 False인 정답을 True라고 예측 (오답)   
**False Negative(FN)** : 실제 True인 정답을 False라고 예측 (오답)   
**True Negative(TN)** : 실제 False인 정답을 False라고 예측 (정답) 
- 정확도(Accuracy)
> **정확도**는 자주 사용되고, 가장 직관적으로 모델의 성능을 나타낼 수 있는 지표이다. 데이터 중에서 실제 데이터의 정답과 모델이 예측한 정답이 같은 비율을 나타낸다. 
![](./images/2022-05-08-17-21-13.png)
❗️문제점-도메인의 편증: 데이터가 불균형할 때 적절하지 못한 지표로써 잘못 사용될 가능성이 있다.
- 정밀도(precision)와 재현율(Sensitivity)
>**정밀도**는 모델이 True라고 예측한 정답 중에서 실제로 True인 비율을 의미한다.
![](./images/2022-05-08-17-26-54.png)    
>**재현율**은 실제 제이터가 true인 것 중에서 모델이 True라고 예측한 비율이다. 
![](./images/2022-05-08-17-29-37.png)   
❗️정밀도와 재현율의 확률은 서로 반대이기 때문에, **두 지표는 trade-off 관계에 있다고 표현한다.** 정밀도를 올리면 재현율이 올라가고, 재현율을 올리면 정밀도가 내려간다. 상황에 따라 다르기 때문에, 각각의 임계치를 정해두고 모델을 평가한다.
- F1-스코어
> 정밀도와 재현율의 임계치를 잘못 설정하여 극단적인 경우로 갈 경우에는, F1-스코어를 사용한다.![](./images/2022-05-08-17-39-28.png)
F1-스코어는 정밀도와 재현율의 중요성이 같다는 가정 하에, 두 지표의 조화 평균으로 만들어진 지표이다.
❗️한쪽으로 치우치지 않는 모델을 만드는 데 유용하다.   

그 외의 다른 평가들
- Fall-out
- ROC곡선(Receiver Operating Characteristic curve)
- AUC(Area Under Curve)
